{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy import sparse\n",
    "import os\n",
    "from sklearn import metrics\n",
    "\n",
    "os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
    "import dgl\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "from dgl.data import DGLDataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_tree = uproot.open(\n",
    "    \"/home2/chenxu/work/corsika/50GeV_1TeV_zen0.gamma.root:tCorsika\"\n",
    ")\n",
    "P_tree = uproot.open(\n",
    "    \"/home2/chenxu/work/corsika/100GeV_10TeV_zen0.proton.root:tCorsika\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_prie = np.array(gamma_tree[\"evth/fLia[312]\"].array()[:, 3])\n",
    "P_prie = np.array(P_tree[\"evth/fLia[312]\"].array()[:, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_secs = gamma_tree[\"secParticles/secParticles.fLia[8]\"].array()\n",
    "P_secs = P_tree[\"secParticles/secParticles.fLia[8]\"].array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "secs = list()\n",
    "nparticle = list()\n",
    "for i in range(len(gamma_secs)):\n",
    "    secs.append(gamma_secs[i])\n",
    "    nparticle.append(len(gamma_secs[i]))\n",
    "for i in range(len(gamma_secs)):\n",
    "    secs.append(P_secs[i])\n",
    "    nparticle.append(len(P_secs[i]))\n",
    "secs = np.array(secs, dtype=object)\n",
    "nparticle = np.array(nparticle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sectype = list()\n",
    "for i in range(100000):\n",
    "    sectype.append(np.floor(np.array(gamma_secs[i])[:, 0] / 1000).astype(int))\n",
    "    sectype.append(np.floor(np.array(P_secs[i])[:, 0] / 1000).astype(int))\n",
    "sectype = np.concatenate(sectype)\n",
    "sectype = list(set(sectype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sectype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "secstypes = [[1, 2, 3], [5, 6], [8, 9, 13, 14, 15, 25, 10, 11, 12, 201, 18]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sec = np.array(P_secs[0])\n",
    "sec = sec[:, :-1]\n",
    "xbins = np.linspace(-500 * 100, 500 * 100, 225)\n",
    "ybins = np.linspace(-500 * 100, 500 * 100, 225)\n",
    "for i in sectype:\n",
    "    print(i)\n",
    "    H, _, _ = np.histogram2d(\n",
    "        sec[:, 4][np.isin((sec[:, 0] / 1000).astype(int), i)],\n",
    "        sec[:, 5][np.isin((sec[:, 0] / 1000).astype(int), i)],\n",
    "        bins=(xbins, ybins),\n",
    "    )\n",
    "    H = H.T\n",
    "    print(np.max(H))\n",
    "    X, Y = np.meshgrid(xbins, ybins)\n",
    "    plt.pcolormesh(X, Y, H)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_log10energy = np.log10(gamma_prie).astype(np.float32)\n",
    "P_log10energy = np.log10(P_prie).astype(np.float32)\n",
    "log10energy = np.concatenate([gamma_log10energy, P_log10energy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "isgamma = np.zeros_like(log10energy, dtype=int)\n",
    "isgamma[: len(gamma_log10energy)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCDataset_dgl(DGLDataset):\n",
    "    def __init__(self, isgamma, secs):\n",
    "        self.secs = secs\n",
    "        self.isgamma = isgamma\n",
    "        self.secstypes = [\n",
    "            [1, 2, 3],\n",
    "            [5, 6],\n",
    "            [8, 9, 13, 14, 15, 25, 10, 11, 12, 201, 18],\n",
    "        ]\n",
    "        self.xmax = 50 * 100\n",
    "        self.ymax = 50 * 100\n",
    "        self.enc = OneHotEncoder()\n",
    "        self.enc.fit(np.arange(3).reshape(-1, 1))\n",
    "        super().__init__(name=\"corsika_data\")\n",
    "\n",
    "    def process(self):\n",
    "        self.graphs = list()\n",
    "        self.isgamma_need = list()\n",
    "        seccount = 0\n",
    "        for secs in tqdm(self.secs, mininterval=1):\n",
    "            secs = np.array(secs)\n",
    "            secs = secs[\n",
    "                np.where(\n",
    "                    (np.abs(secs[:, 4]) < self.xmax) & (np.abs(secs[:, 5]) < self.ymax)\n",
    "                )\n",
    "            ]\n",
    "            secslen = len(secs)\n",
    "            if secslen < 30:\n",
    "                seccount += 1\n",
    "                continue\n",
    "            #             print(secslen)\n",
    "            self.isgamma_need.append(self.isgamma[seccount])\n",
    "            seccount += 1\n",
    "            secstype_new = 0\n",
    "            for secstype in self.secstypes:\n",
    "                secs[:, 0][\n",
    "                    np.isin((secs[:, 0] / 1000).astype(int), secstype)\n",
    "                ] = secstype_new\n",
    "                secstype_new += 1\n",
    "\n",
    "            xdata = np.zeros([secslen, 9], dtype=np.float32)\n",
    "            xdata[:, :3] = self.enc.transform(secs[:, 0].reshape(-1, 1)).toarray()\n",
    "            xdata[:, 3:6] = secs[:, 1:4]\n",
    "            xdata[:, 6:8] = secs[:, 4:6] / self.xmax\n",
    "            xdata[:, 8] = (secs[:, 6] - np.mean(secs[:, 6])) * 30 / self.xmax\n",
    "            src = np.array([n for n in range(secslen) for _ in range(secslen)],dtype=np.int32)\n",
    "            dst = np.array(list(range(secslen))*secslen,dtype=np.int32)\n",
    "            need_del = np.where(src==dst)\n",
    "            src = np.delete(src,need_del[0])\n",
    "            dst = np.delete(dst,need_del[0])\n",
    "            src = torch.tensor(src)\n",
    "            dst = torch.tensor(dst)\n",
    "\n",
    "#             print(src.shape)\n",
    "            g = dgl.graph((src, dst), num_nodes=secslen)\n",
    "            g.ndata[\"xdata\"] = torch.from_numpy(xdata)\n",
    "            self.graphs.append(g)\n",
    "        self.isgamma_need = torch.tensor(self.isgamma_need,dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.graphs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (\n",
    "            self.graphs[index],\n",
    "            self.isgamma_need[index],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_index, test__index = train_test_split(\n",
    "    range(len(isgamma)), random_state=42, test_size=0.3\n",
    ")\n",
    "train_index, val_index = train_test_split(\n",
    "    train_val_index, random_state=42, test_size=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eb6d5311f6f4783b9fc3c616678e49c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/98000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56ded0ec752c46fd810ad72b2308b44f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MCdataset_train = MCDataset_dgl(isgamma[train_index], secs[train_index])\n",
    "MCdataset_val = MCDataset_dgl(isgamma[val_index], secs[val_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = \"/tmp/hky/gnndata_gin_Pgamma/train_data/\"\n",
    "dgl.save_graphs(os.path.join(savepath,f\"graph.bin\"),MCdataset_train.graphs)\n",
    "np.save(os.path.join(savepath,f\"label.npy\"),MCdataset_train.isgamma_need)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = \"/tmp/hky/gnndata_gin_Pgamma/val_data/\"\n",
    "dgl.save_graphs(os.path.join(savepath,f\"graph.bin\"),MCdataset_val.graphs)\n",
    "np.save(os.path.join(savepath,f\"label.npy\"),MCdataset_val.isgamma_need)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32945"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(MCdataset_train.isgamma_need)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = GraphDataLoader(MCdataset_train, batch_size=64, drop_last=False)\n",
    "val_dataloader = GraphDataLoader(MCdataset_val, batch_size=64, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn.pytorch.conv import GINConv\n",
    "from dgl.nn.pytorch.glob import SumPooling, AvgPooling, MaxPooling\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"Construct two-layer MLP-type aggreator for GIN model\"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.linears = nn.ModuleList()\n",
    "        # two-layer MLP\n",
    "        self.linears.append(nn.Linear(input_dim, hidden_dim, bias=False))\n",
    "        self.linears.append(nn.Linear(hidden_dim, output_dim, bias=False))\n",
    "        self.batch_norm = nn.BatchNorm1d((hidden_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = x\n",
    "        h = F.relu(self.batch_norm(self.linears[0](h)))\n",
    "        return self.linears[1](h)\n",
    "\n",
    "\n",
    "class GIN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.ginlayers = nn.ModuleList()\n",
    "        self.batch_norms = nn.ModuleList()\n",
    "        num_layers = 5\n",
    "        # five-layer GCN with two-layer MLP aggregator and sum-neighbor-pooling scheme\n",
    "        for layer in range(num_layers - 1):  # excluding the input layer\n",
    "            if layer == 0:\n",
    "                mlp = MLP(input_dim, hidden_dim, hidden_dim)\n",
    "            else:\n",
    "                mlp = MLP(hidden_dim, hidden_dim, hidden_dim)\n",
    "            self.ginlayers.append(\n",
    "                GINConv(mlp, learn_eps=False)\n",
    "            )  # set to True if learning epsilon\n",
    "            self.batch_norms.append(nn.BatchNorm1d(hidden_dim))\n",
    "        # linear functions for graph sum poolings of output of each layer\n",
    "        self.linear_prediction = nn.ModuleList()\n",
    "        for layer in range(num_layers):\n",
    "            if layer == 0:\n",
    "                self.linear_prediction.append(nn.Linear(input_dim, output_dim))\n",
    "            else:\n",
    "                self.linear_prediction.append(nn.Linear(hidden_dim, output_dim))\n",
    "        self.drop = nn.Dropout(0.5)\n",
    "        self.pool = (\n",
    "            MaxPooling()\n",
    "        )  # change to mean readout (AvgPooling) on social network datasets\n",
    "\n",
    "    def forward(self, g, h):\n",
    "        # list of hidden representation at each layer (including the input layer)\n",
    "        hidden_rep = [h]\n",
    "        for i, layer in enumerate(self.ginlayers):\n",
    "            h = layer(g, h)\n",
    "            h = self.batch_norms[i](h)\n",
    "            h = F.relu(h)\n",
    "            hidden_rep.append(h)\n",
    "        score_over_layer = 0\n",
    "        # perform graph sum pooling over all nodes in each layer\n",
    "        for i, h in enumerate(hidden_rep):\n",
    "            pooled_h = self.pool(g, h)\n",
    "            score_over_layer += self.drop(self.linear_prediction[i](pooled_h))\n",
    "        return score_over_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "loss:0.5153\n"
     ]
    },
    {
     "ename": "DGLError",
     "evalue": "[16:19:30] /opt/dgl/src/runtime/cuda/cuda_device_api.cc:117: Check failed: e == cudaSuccess || e == cudaErrorCudartUnloading: CUDA: out of memory\nStack trace:\n  [bt] (0) /home2/hky/miniconda3/envs/dgl/lib/python3.9/site-packages/dgl/libdgl.so(+0x8b9655) [0x7facd274e655]\n  [bt] (1) /home2/hky/miniconda3/envs/dgl/lib/python3.9/site-packages/dgl/libdgl.so(dgl::runtime::CUDADeviceAPI::AllocDataSpace(DGLContext, unsigned long, unsigned long, DGLDataType)+0x17d) [0x7facd274ffbd]\n  [bt] (2) /home2/hky/miniconda3/envs/dgl/lib/python3.9/site-packages/dgl/libdgl.so(dgl::runtime::NDArray::Empty(std::vector<long, std::allocator<long> >, DGLDataType, DGLContext)+0x170) [0x7facd25c79b0]\n  [bt] (3) /home2/hky/miniconda3/envs/dgl/lib/python3.9/site-packages/dgl/libdgl.so(dgl::aten::NewIdArray(long, DGLContext, unsigned char)+0x6d) [0x7facd21cc05d]\n  [bt] (4) /home2/hky/miniconda3/envs/dgl/lib/python3.9/site-packages/dgl/libdgl.so(std::pair<dgl::runtime::NDArray, dgl::runtime::NDArray> dgl::aten::impl::Sort<(DGLDeviceType)2, int>(dgl::runtime::NDArray, int)+0x6b) [0x7facd2776c7b]\n  [bt] (5) /home2/hky/miniconda3/envs/dgl/lib/python3.9/site-packages/dgl/libdgl.so(dgl::aten::Sort(dgl::runtime::NDArray, int)+0x492) [0x7facd21e33d2]\n  [bt] (6) /home2/hky/miniconda3/envs/dgl/lib/python3.9/site-packages/dgl/libdgl.so(void dgl::aten::impl::COOSort_<(DGLDeviceType)2, int>(dgl::aten::COOMatrix*, bool)+0x394) [0x7facd277f8e4]\n  [bt] (7) /home2/hky/miniconda3/envs/dgl/lib/python3.9/site-packages/dgl/libdgl.so(dgl::aten::COOSort_(dgl::aten::COOMatrix*, bool)+0x354) [0x7facd21d87b4]\n  [bt] (8) /home2/hky/miniconda3/envs/dgl/lib/python3.9/site-packages/dgl/libdgl.so(dgl::aten::COOSort(dgl::aten::COOMatrix, bool)+0x530) [0x7facd277e030]\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDGLError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 29\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batched_graph, labels \u001b[38;5;129;01min\u001b[39;00m val_dataloader:\n\u001b[1;32m     28\u001b[0m     batched_graph, labels \u001b[38;5;241m=\u001b[39m batched_graph\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 29\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatched_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mxdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     pred \u001b[38;5;241m=\u001b[39m m(pred)\n\u001b[1;32m     31\u001b[0m     y_pred\u001b[38;5;241m.\u001b[39mappend(pred[:, \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "File \u001b[0;32m~/miniconda3/envs/dgl/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[35], line 54\u001b[0m, in \u001b[0;36mGIN.forward\u001b[0;34m(self, g, h)\u001b[0m\n\u001b[1;32m     52\u001b[0m hidden_rep \u001b[38;5;241m=\u001b[39m [h]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mginlayers):\n\u001b[0;32m---> 54\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_norms[i](h)\n\u001b[1;32m     56\u001b[0m     h \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(h)\n",
      "File \u001b[0;32m~/miniconda3/envs/dgl/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/dgl/lib/python3.9/site-packages/dgl/nn/pytorch/conv/ginconv.py:151\u001b[0m, in \u001b[0;36mGINConv.forward\u001b[0;34m(self, graph, feat, edge_weight)\u001b[0m\n\u001b[1;32m    149\u001b[0m feat_src, feat_dst \u001b[38;5;241m=\u001b[39m expand_as_pair(feat, graph)\n\u001b[1;32m    150\u001b[0m graph\u001b[38;5;241m.\u001b[39msrcdata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m feat_src\n\u001b[0;32m--> 151\u001b[0m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43maggregate_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_reducer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mneigh\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m rst \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meps) \u001b[38;5;241m*\u001b[39m feat_dst \u001b[38;5;241m+\u001b[39m graph\u001b[38;5;241m.\u001b[39mdstdata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneigh\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/dgl/lib/python3.9/site-packages/dgl/heterograph.py:5110\u001b[0m, in \u001b[0;36mDGLGraph.update_all\u001b[0;34m(self, message_func, reduce_func, apply_node_func, etype)\u001b[0m\n\u001b[1;32m   5108\u001b[0m _, dtid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39mmetagraph\u001b[38;5;241m.\u001b[39mfind_edge(etid)\n\u001b[1;32m   5109\u001b[0m g \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m etype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m[etype]\n\u001b[0;32m-> 5110\u001b[0m ndata \u001b[38;5;241m=\u001b[39m \u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage_passing\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5111\u001b[0m \u001b[43m    \u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapply_node_func\u001b[49m\n\u001b[1;32m   5112\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   5114\u001b[0m     core\u001b[38;5;241m.\u001b[39mis_builtin(reduce_func)\n\u001b[1;32m   5115\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m reduce_func\u001b[38;5;241m.\u001b[39mname \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   5116\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m ndata\n\u001b[1;32m   5117\u001b[0m ):\n\u001b[1;32m   5118\u001b[0m     \u001b[38;5;66;03m# Replace infinity with zero for isolated nodes\u001b[39;00m\n\u001b[1;32m   5119\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ndata\u001b[38;5;241m.\u001b[39mkeys())[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/dgl/lib/python3.9/site-packages/dgl/core.py:388\u001b[0m, in \u001b[0;36mmessage_passing\u001b[0;34m(g, mfunc, rfunc, afunc)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Invoke message passing computation on the whole graph.\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;124;03m    Results from the message passing computation.\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    382\u001b[0m     is_builtin(mfunc)\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m is_builtin(rfunc)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    386\u001b[0m ):\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;66;03m# invoke fused message passing\u001b[39;00m\n\u001b[0;32m--> 388\u001b[0m     ndata \u001b[38;5;241m=\u001b[39m \u001b[43minvoke_gspmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;66;03m# invoke message passing in two separate steps\u001b[39;00m\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;66;03m# message phase\u001b[39;00m\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_builtin(mfunc):\n",
      "File \u001b[0;32m~/miniconda3/envs/dgl/lib/python3.9/site-packages/dgl/core.py:358\u001b[0m, in \u001b[0;36minvoke_gspmm\u001b[0;34m(graph, mfunc, rfunc, srcdata, dstdata, edata)\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# \"copy_e\"\u001b[39;00m\n\u001b[1;32m    357\u001b[0m             x \u001b[38;5;241m=\u001b[39m data_dict_to_list(graph, x, mfunc, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124me\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 358\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {rfunc\u001b[38;5;241m.\u001b[39mout_field: z}\n",
      "File \u001b[0;32m~/miniconda3/envs/dgl/lib/python3.9/site-packages/dgl/ops/spmm.py:215\u001b[0m, in \u001b[0;36m_gen_copy_reduce_func.<locals>.func\u001b[0;34m(g, x)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunc\u001b[39m(g, x):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary_op \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcopy_u\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgspmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcopy_lhs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m gspmm(g, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcopy_rhs\u001b[39m\u001b[38;5;124m\"\u001b[39m, reduce_op, \u001b[38;5;28;01mNone\u001b[39;00m, x)\n",
      "File \u001b[0;32m~/miniconda3/envs/dgl/lib/python3.9/site-packages/dgl/ops/spmm.py:79\u001b[0m, in \u001b[0;36mgspmm\u001b[0;34m(g, op, reduce_op, lhs_data, rhs_data)\u001b[0m\n\u001b[1;32m     77\u001b[0m         lhs_data, rhs_data \u001b[38;5;241m=\u001b[39m reshape_lhs_rhs(lhs_data, rhs_data)\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;66;03m# With max and min reducers infinity will be returned for zero degree nodes\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mgspmm_internal\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m        \u001b[49m\u001b[43mg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m        \u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mreduce_op\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mreduce_op\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlhs_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrhs_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;66;03m# lhs_data or rhs_data is None only in unary functions like ``copy-u`` or ``copy_e``\u001b[39;00m\n\u001b[1;32m     88\u001b[0m     lhs_data \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     89\u001b[0m         [\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m g\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39mnumber_of_ntypes()\n\u001b[1;32m     90\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m lhs_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     91\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m lhs_data\n\u001b[1;32m     92\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/dgl/lib/python3.9/site-packages/dgl/backend/pytorch/sparse.py:1032\u001b[0m, in \u001b[0;36mgspmm\u001b[0;34m(gidx, op, reduce_op, lhs_data, rhs_data)\u001b[0m\n\u001b[1;32m   1030\u001b[0m args \u001b[38;5;241m=\u001b[39m _cast_if_autocast_enabled(gidx, op, reduce_op, lhs_data, rhs_data)\n\u001b[1;32m   1031\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _disable_autocast_if_enabled():\n\u001b[0;32m-> 1032\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mGSpMM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dgl/lib/python3.9/site-packages/torch/autograd/function.py:506\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    505\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 506\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39msetup_context \u001b[38;5;241m==\u001b[39m _SingleLevelFunction\u001b[38;5;241m.\u001b[39msetup_context:\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    510\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    511\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    512\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/dgl/lib/python3.9/site-packages/dgl/backend/pytorch/sparse.py:165\u001b[0m, in \u001b[0;36mGSpMM.forward\u001b[0;34m(ctx, gidx, op, reduce_op, X, Y)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(ctx, gidx, op, reduce_op, X, Y):\n\u001b[0;32m--> 165\u001b[0m     out, (argX, argY) \u001b[38;5;241m=\u001b[39m \u001b[43m_gspmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgidx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m     reduce_last \u001b[38;5;241m=\u001b[39m _need_reduce_last_dim(X, Y)\n\u001b[1;32m    167\u001b[0m     X_shape \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dgl/lib/python3.9/site-packages/dgl/_sparse_ops.py:239\u001b[0m, in \u001b[0;36m_gspmm\u001b[0;34m(gidx, op, reduce_op, u, e)\u001b[0m\n\u001b[1;32m    237\u001b[0m arg_e_nd \u001b[38;5;241m=\u001b[39m to_dgl_nd_for_write(arg_e)\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gidx\u001b[38;5;241m.\u001b[39mnum_edges(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 239\u001b[0m     \u001b[43m_CAPI_DGLKernelSpMM\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgidx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreduce_op\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mto_dgl_nd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43muse_u\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mto_dgl_nd\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43muse_e\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mto_dgl_nd_for_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_u_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_e_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# NOTE(zihao): actually we can avoid the following step, because arg_*_nd\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# refers to the data that stores arg_*. After we call _CAPI_DGLKernelSpMM,\u001b[39;00m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;66;03m# arg_* should have already been changed. But we found this doesn't work\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;66;03m# The workaround is proposed by Jinjing, and we still need to investigate\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;66;03m# where the problem is.\u001b[39;00m\n\u001b[1;32m    256\u001b[0m arg_u \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m arg_u \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m F\u001b[38;5;241m.\u001b[39mzerocopy_from_dgl_ndarray(arg_u_nd)\n",
      "File \u001b[0;32mdgl/_ffi/_cython/./function.pxi:295\u001b[0m, in \u001b[0;36mdgl._ffi._cy3.core.FunctionBase.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mdgl/_ffi/_cython/./function.pxi:241\u001b[0m, in \u001b[0;36mdgl._ffi._cy3.core.FuncCall\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mDGLError\u001b[0m: [16:19:30] /opt/dgl/src/runtime/cuda/cuda_device_api.cc:117: Check failed: e == cudaSuccess || e == cudaErrorCudartUnloading: CUDA: out of memory\nStack trace:\n  [bt] (0) /home2/hky/miniconda3/envs/dgl/lib/python3.9/site-packages/dgl/libdgl.so(+0x8b9655) [0x7facd274e655]\n  [bt] (1) /home2/hky/miniconda3/envs/dgl/lib/python3.9/site-packages/dgl/libdgl.so(dgl::runtime::CUDADeviceAPI::AllocDataSpace(DGLContext, unsigned long, unsigned long, DGLDataType)+0x17d) [0x7facd274ffbd]\n  [bt] (2) /home2/hky/miniconda3/envs/dgl/lib/python3.9/site-packages/dgl/libdgl.so(dgl::runtime::NDArray::Empty(std::vector<long, std::allocator<long> >, DGLDataType, DGLContext)+0x170) [0x7facd25c79b0]\n  [bt] (3) /home2/hky/miniconda3/envs/dgl/lib/python3.9/site-packages/dgl/libdgl.so(dgl::aten::NewIdArray(long, DGLContext, unsigned char)+0x6d) [0x7facd21cc05d]\n  [bt] (4) /home2/hky/miniconda3/envs/dgl/lib/python3.9/site-packages/dgl/libdgl.so(std::pair<dgl::runtime::NDArray, dgl::runtime::NDArray> dgl::aten::impl::Sort<(DGLDeviceType)2, int>(dgl::runtime::NDArray, int)+0x6b) [0x7facd2776c7b]\n  [bt] (5) /home2/hky/miniconda3/envs/dgl/lib/python3.9/site-packages/dgl/libdgl.so(dgl::aten::Sort(dgl::runtime::NDArray, int)+0x492) [0x7facd21e33d2]\n  [bt] (6) /home2/hky/miniconda3/envs/dgl/lib/python3.9/site-packages/dgl/libdgl.so(void dgl::aten::impl::COOSort_<(DGLDeviceType)2, int>(dgl::aten::COOMatrix*, bool)+0x394) [0x7facd277f8e4]\n  [bt] (7) /home2/hky/miniconda3/envs/dgl/lib/python3.9/site-packages/dgl/libdgl.so(dgl::aten::COOSort_(dgl::aten::COOMatrix*, bool)+0x354) [0x7facd21d87b4]\n  [bt] (8) /home2/hky/miniconda3/envs/dgl/lib/python3.9/site-packages/dgl/libdgl.so(dgl::aten::COOSort(dgl::aten::COOMatrix, bool)+0x530) [0x7facd277e030]\n\n"
     ]
    }
   ],
   "source": [
    "model = GIN(9, 64, 2).to(device)\n",
    "maxtpoch = 100\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2, weight_decay=1e-4)\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer, maxtpoch, eta_min=1e-5\n",
    ")\n",
    "for epoch in range(maxtpoch):\n",
    "    sumloss = list()\n",
    "    print(epoch)\n",
    "    for batched_graph, labels in train_dataloader:\n",
    "        batched_graph, labels = batched_graph.to(device), labels.to(device)\n",
    "        pred = model(batched_graph, batched_graph.ndata[\"xdata\"])\n",
    "        loss = F.cross_entropy(pred, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        sumloss.append(loss.item())\n",
    "        optimizer.step()\n",
    "    lr_scheduler.step()\n",
    "    print(f\"loss:{np.mean(sumloss):.4f}\")\n",
    "    model.eval()\n",
    "    count1 = 0\n",
    "    count2 = 0\n",
    "    m = nn.Softmax(dim=1)\n",
    "    y_pred = list()\n",
    "    y_orgin = list()\n",
    "    with torch.no_grad():\n",
    "        for batched_graph, labels in val_dataloader:\n",
    "            batched_graph, labels = batched_graph.to(device), labels.to(device)\n",
    "            pred = model(batched_graph, batched_graph.ndata[\"xdata\"])\n",
    "            pred = m(pred)\n",
    "            y_pred.append(pred[:, 1].cpu().numpy())\n",
    "            y_orgin.append(labels.cpu().numpy())\n",
    "    y_pred = np.concatenate(y_pred)\n",
    "    y_orgin = np.concatenate(y_orgin)\n",
    "    auc = metrics.roc_auc_score(y_orgin, y_pred)\n",
    "    print(f\"auc:{auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "count1 = 0\n",
    "count2 = 0\n",
    "m = nn.Softmax(dim=1)\n",
    "y_pred = list()\n",
    "y_orgin = list()\n",
    "with torch.no_grad():\n",
    "    for batched_graph, labels in test_dataloader:\n",
    "        batched_graph, labels = batched_graph.to(device), labels.to(device)\n",
    "        pred = model(batched_graph, batched_graph.ndata[\"xdata\"])\n",
    "        pred = m(pred)\n",
    "        y_pred.append(pred[:, 1].cpu().numpy())\n",
    "        y_orgin.append(labels.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.concatenate(y_pred)\n",
    "y_orgin = np.concatenate(y_orgin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "fpr_maxpool, tpr_maxpool, _ = metrics.roc_curve(y_orgin, y_pred)\n",
    "auc = metrics.roc_auc_score(y_orgin, y_pred)\n",
    "plt.plot(fpr_maxpool, tpr_maxpool, label=f\"gin_maxpool, AUC={auc:.4f}\")\n",
    "plt.xlabel(\"fpr\")\n",
    "plt.ylabel(\"tpr \")\n",
    "plt.legend()\n",
    "plt.xlim(0, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn.pytorch.conv import GINConv\n",
    "from dgl.nn.pytorch.glob import SumPooling, AvgPooling, MaxPooling\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"Construct two-layer MLP-type aggreator for GIN model\"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.linears = nn.ModuleList()\n",
    "        # two-layer MLP\n",
    "        self.linears.append(nn.Linear(input_dim, hidden_dim, bias=False))\n",
    "        self.linears.append(nn.Linear(hidden_dim, output_dim, bias=False))\n",
    "        self.batch_norm = nn.BatchNorm1d((hidden_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = x\n",
    "        h = F.relu(self.batch_norm(self.linears[0](h)))\n",
    "        return self.linears[1](h)\n",
    "\n",
    "\n",
    "class GIN_avg(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.ginlayers = nn.ModuleList()\n",
    "        self.batch_norms = nn.ModuleList()\n",
    "        num_layers = 5\n",
    "        # five-layer GCN with two-layer MLP aggregator and sum-neighbor-pooling scheme\n",
    "        for layer in range(num_layers - 1):  # excluding the input layer\n",
    "            if layer == 0:\n",
    "                mlp = MLP(input_dim, hidden_dim, hidden_dim)\n",
    "            else:\n",
    "                mlp = MLP(hidden_dim, hidden_dim, hidden_dim)\n",
    "            self.ginlayers.append(\n",
    "                GINConv(mlp, learn_eps=False)\n",
    "            )  # set to True if learning epsilon\n",
    "            self.batch_norms.append(nn.BatchNorm1d(hidden_dim))\n",
    "        # linear functions for graph sum poolings of output of each layer\n",
    "        self.linear_prediction = nn.ModuleList()\n",
    "        for layer in range(num_layers):\n",
    "            if layer == 0:\n",
    "                self.linear_prediction.append(nn.Linear(input_dim, output_dim))\n",
    "            else:\n",
    "                self.linear_prediction.append(nn.Linear(hidden_dim, output_dim))\n",
    "        self.drop = nn.Dropout(0.5)\n",
    "        self.pool = (\n",
    "            AvgPooling()\n",
    "        )  # change to mean readout (AvgPooling) on social network datasets\n",
    "\n",
    "    def forward(self, g, h):\n",
    "        # list of hidden representation at each layer (including the input layer)\n",
    "        hidden_rep = [h]\n",
    "        for i, layer in enumerate(self.ginlayers):\n",
    "            h = layer(g, h)\n",
    "            h = self.batch_norms[i](h)\n",
    "            h = F.relu(h)\n",
    "            hidden_rep.append(h)\n",
    "        score_over_layer = 0\n",
    "        # perform graph sum pooling over all nodes in each layer\n",
    "        for i, h in enumerate(hidden_rep):\n",
    "            pooled_h = self.pool(g, h)\n",
    "            score_over_layer += self.drop(self.linear_prediction[i](pooled_h))\n",
    "        return score_over_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "loss:0.4324\n",
      "1\n",
      "loss:0.3706\n",
      "2\n",
      "loss:0.3502\n",
      "3\n",
      "loss:0.3443\n",
      "4\n",
      "loss:0.3329\n",
      "5\n",
      "loss:0.3246\n",
      "6\n",
      "loss:0.3279\n",
      "7\n",
      "loss:0.3191\n",
      "8\n",
      "loss:0.3172\n",
      "9\n",
      "loss:0.3073\n",
      "10\n",
      "loss:0.3056\n",
      "11\n",
      "loss:0.3079\n",
      "12\n",
      "loss:0.3047\n",
      "13\n",
      "loss:0.3003\n",
      "14\n",
      "loss:0.2918\n",
      "15\n",
      "loss:0.2909\n",
      "16\n",
      "loss:0.2884\n",
      "17\n",
      "loss:0.2810\n",
      "18\n",
      "loss:0.2816\n",
      "19\n",
      "loss:0.2813\n",
      "20\n",
      "loss:0.2861\n",
      "21\n",
      "loss:0.2830\n",
      "22\n",
      "loss:0.2765\n",
      "23\n",
      "loss:0.2739\n",
      "24\n",
      "loss:0.2898\n",
      "25\n",
      "loss:0.2817\n",
      "26\n",
      "loss:0.2743\n",
      "27\n",
      "loss:0.2746\n",
      "28\n",
      "loss:0.2709\n",
      "29\n",
      "loss:0.2706\n",
      "30\n",
      "loss:0.2723\n",
      "31\n",
      "loss:0.2707\n",
      "32\n",
      "loss:0.2713\n",
      "33\n",
      "loss:0.2653\n",
      "34\n",
      "loss:0.2675\n",
      "35\n",
      "loss:0.2676\n",
      "36\n",
      "loss:0.2712\n",
      "37\n",
      "loss:0.2656\n",
      "38\n",
      "loss:0.2637\n",
      "39\n",
      "loss:0.2604\n",
      "40\n",
      "loss:0.2668\n",
      "41\n",
      "loss:0.2594\n",
      "42\n",
      "loss:0.2620\n",
      "43\n",
      "loss:0.2619\n",
      "44\n",
      "loss:0.2612\n",
      "45\n",
      "loss:0.2622\n",
      "46\n",
      "loss:0.2570\n",
      "47\n",
      "loss:0.2582\n",
      "48\n",
      "loss:0.2572\n",
      "49\n",
      "loss:0.2570\n",
      "50\n",
      "loss:0.2542\n",
      "51\n",
      "loss:0.2766\n",
      "52\n",
      "loss:0.2741\n",
      "53\n",
      "loss:0.2662\n",
      "54\n",
      "loss:0.2652\n",
      "55\n",
      "loss:0.2625\n",
      "56\n",
      "loss:0.2599\n",
      "57\n",
      "loss:0.2587\n",
      "58\n",
      "loss:0.2568\n",
      "59\n",
      "loss:0.2583\n",
      "60\n",
      "loss:0.2601\n",
      "61\n",
      "loss:0.2539\n",
      "62\n",
      "loss:0.2525\n",
      "63\n",
      "loss:0.2533\n",
      "64\n",
      "loss:0.2548\n",
      "65\n",
      "loss:0.2516\n",
      "66\n",
      "loss:0.2491\n",
      "67\n",
      "loss:0.2489\n",
      "68\n",
      "loss:0.2534\n",
      "69\n",
      "loss:0.2518\n",
      "70\n",
      "loss:0.2500\n",
      "71\n",
      "loss:0.2459\n",
      "72\n",
      "loss:0.2470\n",
      "73\n",
      "loss:0.2457\n",
      "74\n",
      "loss:0.2454\n",
      "75\n",
      "loss:0.2468\n",
      "76\n",
      "loss:0.2462\n",
      "77\n",
      "loss:0.2572\n",
      "78\n",
      "loss:0.2436\n",
      "79\n",
      "loss:0.2479\n",
      "80\n",
      "loss:0.2497\n",
      "81\n",
      "loss:0.2481\n",
      "82\n",
      "loss:0.2450\n",
      "83\n",
      "loss:0.2470\n",
      "84\n",
      "loss:0.2419\n",
      "85\n",
      "loss:0.2424\n",
      "86\n",
      "loss:0.2493\n",
      "87\n",
      "loss:0.2430\n",
      "88\n",
      "loss:0.2469\n",
      "89\n",
      "loss:0.2435\n",
      "90\n",
      "loss:0.2412\n",
      "91\n",
      "loss:0.2437\n",
      "92\n",
      "loss:0.2347\n",
      "93\n",
      "loss:0.2397\n",
      "94\n",
      "loss:0.2389\n",
      "95\n",
      "loss:0.2394\n",
      "96\n",
      "loss:0.2387\n",
      "97\n",
      "loss:0.2418\n",
      "98\n",
      "loss:0.2458\n",
      "99\n",
      "loss:0.2404\n"
     ]
    }
   ],
   "source": [
    "model = GIN_avg(9, 64, 2).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "for epoch in range(100):\n",
    "    sumloss = list()\n",
    "    print(epoch)\n",
    "    for batched_graph, labels in train_dataloader:\n",
    "        batched_graph, labels = batched_graph.to(device), labels.to(device)\n",
    "        pred = model(batched_graph, batched_graph.ndata[\"xdata\"])\n",
    "        loss = F.cross_entropy(pred, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        sumloss.append(loss.item())\n",
    "        optimizer.step()\n",
    "    print(f\"loss:{np.mean(sumloss):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "count1 = 0\n",
    "count2 = 0\n",
    "m = nn.Softmax(dim=1)\n",
    "y_pred = list()\n",
    "y_orgin = list()\n",
    "with torch.no_grad():\n",
    "    for batched_graph, labels in test_dataloader:\n",
    "        batched_graph, labels = batched_graph.to(device), labels.to(device)\n",
    "        pred = model(batched_graph, batched_graph.ndata[\"xdata\"])\n",
    "        pred = m(pred)\n",
    "        y_pred.append(pred[:, 1].cpu().numpy())\n",
    "        y_orgin.append(labels.cpu().numpy())\n",
    "y_pred = np.concatenate(y_pred)\n",
    "y_orgin = np.concatenate(y_orgin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "fpr_avgpool, tpr_avgpool, _ = metrics.roc_curve(y_orgin, y_pred)\n",
    "auc_avg = metrics.roc_auc_score(y_orgin, y_pred)\n",
    "plt.plot(fpr_maxpool, tpr_maxpool, label=f\"gin_maxpool, AUC={auc:.4f}\")\n",
    "plt.plot(fpr_avgpool, tpr_avgpool, label=f\"gin_avgpool, AUC={auc_avg:.4f}\")\n",
    "plt.xlabel(\"fpr\")\n",
    "plt.ylabel(\"tpr\")\n",
    "plt.legend()\n",
    "plt.xlim(0, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ogb.graphproppred.mol_encoder import AtomEncoder, BondEncoder\n",
    "\n",
    "\n",
    "class MLP(nn.Sequential):\n",
    "    r\"\"\"\n",
    "\n",
    "    Description\n",
    "    -----------\n",
    "    From equation (5) in \"DeeperGCN: All You Need to Train Deeper GCNs <https://arxiv.org/abs/2006.07739>\"\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, channels, act=\"relu\", dropout=0.0, bias=True):\n",
    "        layers = []\n",
    "\n",
    "        for i in range(1, len(channels)):\n",
    "            layers.append(nn.Linear(channels[i - 1], channels[i], bias))\n",
    "            if i < len(channels) - 1:\n",
    "                layers.append(nn.BatchNorm1d(channels[i], affine=True))\n",
    "                layers.append(nn.ReLU())\n",
    "                layers.append(nn.Dropout(dropout))\n",
    "\n",
    "        super(MLP, self).__init__(*layers)\n",
    "\n",
    "\n",
    "class MessageNorm(nn.Module):\n",
    "    r\"\"\"\n",
    "\n",
    "    Description\n",
    "    -----------\n",
    "    Message normalization was introduced in \"DeeperGCN: All You Need to Train Deeper GCNs <https://arxiv.org/abs/2006.07739>\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    learn_scale: bool\n",
    "        Whether s is a learnable scaling factor or not. Default is False.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, learn_scale=False):\n",
    "        super(MessageNorm, self).__init__()\n",
    "        self.scale = nn.Parameter(torch.FloatTensor([1.0]), requires_grad=learn_scale)\n",
    "\n",
    "    def forward(self, feats, msg, p=2):\n",
    "        msg = F.normalize(msg, p=2, dim=-1)\n",
    "        feats_norm = feats.norm(p=p, dim=-1, keepdim=True)\n",
    "        return msg * feats_norm * self.scale\n",
    "\n",
    "\n",
    "class GENConv(nn.Module):\n",
    "    r\"\"\"\n",
    "\n",
    "    Description\n",
    "    -----------\n",
    "    Generalized Message Aggregator was introduced in \"DeeperGCN: All You Need to Train Deeper GCNs <https://arxiv.org/abs/2006.07739>\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_dim: int\n",
    "        Input size.\n",
    "    out_dim: int\n",
    "        Output size.\n",
    "    aggregator: str\n",
    "        Type of aggregation. Default is 'softmax'.\n",
    "    beta: float\n",
    "        A continuous variable called an inverse temperature. Default is 1.0.\n",
    "    learn_beta: bool\n",
    "        Whether beta is a learnable variable or not. Default is False.\n",
    "    p: float\n",
    "        Initial power for power mean aggregation. Default is 1.0.\n",
    "    learn_p: bool\n",
    "        Whether p is a learnable variable or not. Default is False.\n",
    "    msg_norm: bool\n",
    "        Whether message normalization is used. Default is False.\n",
    "    learn_msg_scale: bool\n",
    "        Whether s is a learnable scaling factor or not in message normalization. Default is False.\n",
    "    mlp_layers: int\n",
    "        The number of MLP layers. Default is 1.\n",
    "    eps: float\n",
    "        A small positive constant in message construction function. Default is 1e-7.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_dim,\n",
    "        out_dim,\n",
    "        aggregator=\"softmax\",\n",
    "        beta=1.0,\n",
    "        learn_beta=False,\n",
    "        p=1.0,\n",
    "        learn_p=False,\n",
    "        msg_norm=False,\n",
    "        learn_msg_scale=False,\n",
    "        mlp_layers=1,\n",
    "        eps=1e-7,\n",
    "    ):\n",
    "        super(GENConv, self).__init__()\n",
    "\n",
    "        self.aggr = aggregator\n",
    "        self.eps = eps\n",
    "\n",
    "        channels = [in_dim]\n",
    "        for _ in range(mlp_layers - 1):\n",
    "            channels.append(in_dim * 2)\n",
    "        channels.append(out_dim)\n",
    "\n",
    "        self.mlp = MLP(channels)\n",
    "        self.msg_norm = MessageNorm(learn_msg_scale) if msg_norm else None\n",
    "\n",
    "        self.beta = (\n",
    "            nn.Parameter(torch.Tensor([beta]), requires_grad=True)\n",
    "            if learn_beta and self.aggr == \"softmax\"\n",
    "            else beta\n",
    "        )\n",
    "        self.p = nn.Parameter(torch.Tensor([p]), requires_grad=True) if learn_p else p\n",
    "\n",
    "        self.edge_encoder = BondEncoder(in_dim)\n",
    "\n",
    "    def forward(self, g, node_feats, edge_feats):\n",
    "        with g.local_scope():\n",
    "            # Node and edge feature size need to match.\n",
    "            g.ndata[\"h\"] = node_feats\n",
    "            g.edata[\"h\"] = self.edge_encoder(edge_feats)\n",
    "            g.apply_edges(fn.u_add_e(\"h\", \"h\", \"m\"))\n",
    "\n",
    "            if self.aggr == \"softmax\":\n",
    "                g.edata[\"m\"] = F.relu(g.edata[\"m\"]) + self.eps\n",
    "                g.edata[\"a\"] = edge_softmax(g, g.edata[\"m\"] * self.beta)\n",
    "                g.update_all(\n",
    "                    lambda edge: {\"x\": edge.data[\"m\"] * edge.data[\"a\"]},\n",
    "                    fn.sum(\"x\", \"m\"),\n",
    "                )\n",
    "\n",
    "            elif self.aggr == \"power\":\n",
    "                minv, maxv = 1e-7, 1e1\n",
    "                torch.clamp_(g.edata[\"m\"], minv, maxv)\n",
    "                g.update_all(\n",
    "                    lambda edge: {\"x\": torch.pow(edge.data[\"m\"], self.p)},\n",
    "                    fn.mean(\"x\", \"m\"),\n",
    "                )\n",
    "                torch.clamp_(g.ndata[\"m\"], minv, maxv)\n",
    "                g.ndata[\"m\"] = torch.pow(g.ndata[\"m\"], self.p)\n",
    "\n",
    "            else:\n",
    "                raise NotImplementedError(f\"Aggregator {self.aggr} is not supported.\")\n",
    "\n",
    "            if self.msg_norm is not None:\n",
    "                g.ndata[\"m\"] = self.msg_norm(node_feats, g.ndata[\"m\"])\n",
    "\n",
    "            feats = node_feats + g.ndata[\"m\"]\n",
    "\n",
    "            return self.mlp(feats)\n",
    "\n",
    "\n",
    "class DeeperGCN(nn.Module):\n",
    "    r\"\"\"\n",
    "\n",
    "    Description\n",
    "    -----------\n",
    "    Introduced in \"DeeperGCN: All You Need to Train Deeper GCNs <https://arxiv.org/abs/2006.07739>\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    node_feat_dim: int\n",
    "        Size of node feature.\n",
    "    edge_feat_dim: int\n",
    "        Size of edge feature.\n",
    "    hid_dim: int\n",
    "        Size of hidden representations.\n",
    "    out_dim: int\n",
    "        Size of output.\n",
    "    num_layers: int\n",
    "        Number of graph convolutional layers.\n",
    "    dropout: float\n",
    "        Dropout rate. Default is 0.\n",
    "    beta: float\n",
    "        A continuous variable called an inverse temperature. Default is 1.0.\n",
    "    learn_beta: bool\n",
    "        Whether beta is a learnable weight. Default is False.\n",
    "    aggr: str\n",
    "        Type of aggregation. Default is 'softmax'.\n",
    "    mlp_layers: int\n",
    "        Number of MLP layers in message normalization. Default is 1.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        node_feat_dim,\n",
    "        edge_feat_dim,\n",
    "        hid_dim,\n",
    "        out_dim,\n",
    "        num_layers,\n",
    "        dropout=0.0,\n",
    "        beta=1.0,\n",
    "        learn_beta=False,\n",
    "        aggr=\"softmax\",\n",
    "        mlp_layers=1,\n",
    "    ):\n",
    "        super(DeeperGCN, self).__init__()\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        self.gcns = nn.ModuleList()\n",
    "        self.norms = nn.ModuleList()\n",
    "\n",
    "        for _ in range(self.num_layers):\n",
    "            conv = GENConv(\n",
    "                in_dim=hid_dim,\n",
    "                out_dim=hid_dim,\n",
    "                aggregator=aggr,\n",
    "                beta=beta,\n",
    "                learn_beta=learn_beta,\n",
    "                mlp_layers=mlp_layers,\n",
    "            )\n",
    "\n",
    "            self.gcns.append(conv)\n",
    "            self.norms.append(nn.BatchNorm1d(hid_dim, affine=True))\n",
    "\n",
    "        self.node_encoder = AtomEncoder(hid_dim)\n",
    "        self.pooling = AvgPooling()\n",
    "        self.output = nn.Linear(hid_dim, out_dim)\n",
    "\n",
    "    def forward(self, g, edge_feats, node_feats=None):\n",
    "        with g.local_scope():\n",
    "            hv = self.node_encoder(node_feats)\n",
    "            he = edge_feats\n",
    "\n",
    "            for layer in range(self.num_layers):\n",
    "                hv1 = self.norms[layer](hv)\n",
    "                hv1 = F.relu(hv1)\n",
    "                hv1 = F.dropout(hv1, p=self.dropout, training=self.training)\n",
    "                hv = self.gcns[layer](g, hv1, he) + hv\n",
    "\n",
    "            h_g = self.pooling(g, hv)\n",
    "\n",
    "            return self.output(h_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batched_graph, labels \u001b[38;5;129;01min\u001b[39;00m train_dataloader:\n\u001b[1;32m     14\u001b[0m     batched_graph, labels \u001b[38;5;241m=\u001b[39m batched_graph\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 15\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatched_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mxdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m#         print(pred.shape)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(pred, labels)\n",
      "File \u001b[0;32m~/miniconda3/envs/dgl/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[61], line 230\u001b[0m, in \u001b[0;36mDeeperGCN.forward\u001b[0;34m(self, g, edge_feats, node_feats)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, g, edge_feats, node_feats\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m g\u001b[38;5;241m.\u001b[39mlocal_scope():\n\u001b[0;32m--> 230\u001b[0m         hv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_feats\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m         he \u001b[38;5;241m=\u001b[39m edge_feats\n\u001b[1;32m    233\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers):\n",
      "File \u001b[0;32m~/miniconda3/envs/dgl/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/dgl/lib/python3.9/site-packages/ogb/graphproppred/mol_encoder.py:21\u001b[0m, in \u001b[0;36mAtomEncoder.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     20\u001b[0m     x_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 21\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m[\u001b[38;5;241m1\u001b[39m]):\n\u001b[1;32m     22\u001b[0m         x_embedding \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39matom_embedding_list[i](x[:,i])\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x_embedding\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "model = DeeperGCN(\n",
    "    9,\n",
    "    0,\n",
    "    64,\n",
    "    2,\n",
    "    5,\n",
    "    0.5,\n",
    ").to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2, weight_decay=5e-4)\n",
    "for epoch in range(100):\n",
    "    sumloss = list()\n",
    "    print(epoch)\n",
    "    for batched_graph, labels in train_dataloader:\n",
    "        batched_graph, labels = batched_graph.to(device), labels.to(device)\n",
    "        pred = model(batched_graph, batched_graph.ndata[\"xdata\"])\n",
    "        #         print(pred.shape)\n",
    "        loss = F.cross_entropy(pred, labels)\n",
    "        #         print(loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        sumloss.append(loss.item())\n",
    "        optimizer.step()\n",
    "    print(f\"loss:{np.mean(sumloss):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dgl",
   "language": "python",
   "name": "dgl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
