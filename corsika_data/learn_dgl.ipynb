{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29258e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
    "import dgl\n",
    "import dgl.data\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c1c24d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading /home2/hky/.dgl/GINDataset.zip from https://raw.githubusercontent.com/weihua916/powerful-gnns/master/dataset.zip...\n",
      "Extracting file to /home2/hky/.dgl/GINDataset\n",
      "Downloading /home2/hky/.dgl/GINDataset.zip from https://raw.githubusercontent.com/weihua916/powerful-gnns/master/dataset.zip...\n",
      "Extracting file to /home2/hky/.dgl/GINDataset\n"
     ]
    }
   ],
   "source": [
    "# Generate a synthetic dataset with 10000 graphs, ranging from 10 to 500 nodes.\n",
    "dataset = dgl.data.GINDataset(\"PROTEINS\", self_loop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30825b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node feature dimensionality: 3\n",
      "Number of graph categories: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Node feature dimensionality:\", dataset.dim_nfeats)\n",
    "print(\"Number of graph categories:\", dataset.gclasses)\n",
    "\n",
    "\n",
    "from dgl.dataloading import GraphDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85ce2d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node features\n",
      "{'train_mask': tensor([ True,  True,  True,  ..., False, False, False]), 'val_mask': tensor([False, False, False,  ..., False, False, False]), 'test_mask': tensor([False, False, False,  ...,  True,  True,  True]), 'label': tensor([3, 4, 4,  ..., 3, 3, 3]), 'feat': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "Edge features\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "print(\"Node features\")\n",
    "print(g.ndata)\n",
    "print(\"Edge features\")\n",
    "print(g.edata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f28c3150",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn import GraphConv\n",
    "\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GraphConv(in_feats, h_feats)\n",
    "        self.conv2 = GraphConv(h_feats, num_classes)\n",
    "\n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        return h\n",
    "\n",
    "\n",
    "# Create the model with given dimensions\n",
    "model = GCN(g.ndata[\"feat\"].shape[1], 16, dataset.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a11aa2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/hky/miniconda3/envs/dgl/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 0, loss: 1.945, val acc: 0.160 (best 0.160), test acc: 0.165 (best 0.165)\n",
      "In epoch 5, loss: 1.881, val acc: 0.400 (best 0.448), test acc: 0.452 (best 0.479)\n",
      "In epoch 10, loss: 1.789, val acc: 0.476 (best 0.476), test acc: 0.497 (best 0.497)\n",
      "In epoch 15, loss: 1.674, val acc: 0.544 (best 0.544), test acc: 0.569 (best 0.569)\n",
      "In epoch 20, loss: 1.537, val acc: 0.600 (best 0.600), test acc: 0.625 (best 0.625)\n",
      "In epoch 25, loss: 1.382, val acc: 0.654 (best 0.654), test acc: 0.665 (best 0.665)\n",
      "In epoch 30, loss: 1.216, val acc: 0.688 (best 0.688), test acc: 0.706 (best 0.706)\n",
      "In epoch 35, loss: 1.046, val acc: 0.714 (best 0.714), test acc: 0.725 (best 0.725)\n",
      "In epoch 40, loss: 0.882, val acc: 0.740 (best 0.740), test acc: 0.750 (best 0.750)\n",
      "In epoch 45, loss: 0.731, val acc: 0.750 (best 0.750), test acc: 0.762 (best 0.760)\n",
      "In epoch 50, loss: 0.598, val acc: 0.750 (best 0.750), test acc: 0.769 (best 0.760)\n",
      "In epoch 55, loss: 0.485, val acc: 0.756 (best 0.758), test acc: 0.777 (best 0.775)\n",
      "In epoch 60, loss: 0.393, val acc: 0.762 (best 0.764), test acc: 0.779 (best 0.779)\n",
      "In epoch 65, loss: 0.318, val acc: 0.766 (best 0.766), test acc: 0.781 (best 0.781)\n",
      "In epoch 70, loss: 0.259, val acc: 0.766 (best 0.770), test acc: 0.780 (best 0.781)\n",
      "In epoch 75, loss: 0.212, val acc: 0.770 (best 0.772), test acc: 0.784 (best 0.782)\n",
      "In epoch 80, loss: 0.176, val acc: 0.774 (best 0.774), test acc: 0.785 (best 0.785)\n",
      "In epoch 85, loss: 0.147, val acc: 0.774 (best 0.774), test acc: 0.782 (best 0.785)\n",
      "In epoch 90, loss: 0.124, val acc: 0.778 (best 0.778), test acc: 0.780 (best 0.780)\n",
      "In epoch 95, loss: 0.105, val acc: 0.778 (best 0.780), test acc: 0.780 (best 0.779)\n"
     ]
    }
   ],
   "source": [
    "def train(g, model):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    best_val_acc = 0\n",
    "    best_test_acc = 0\n",
    "\n",
    "    features = g.ndata[\"feat\"]\n",
    "    labels = g.ndata[\"label\"]\n",
    "    train_mask = g.ndata[\"train_mask\"]\n",
    "    val_mask = g.ndata[\"val_mask\"]\n",
    "    test_mask = g.ndata[\"test_mask\"]\n",
    "    for e in range(100):\n",
    "        # Forward\n",
    "        logits = model(g, features)\n",
    "\n",
    "        # Compute prediction\n",
    "        pred = logits.argmax(1)\n",
    "\n",
    "        # Compute loss\n",
    "        # Note that you should only compute the losses of the nodes in the training set.\n",
    "        loss = F.cross_entropy(logits[train_mask], labels[train_mask])\n",
    "\n",
    "        # Compute accuracy on training/validation/test\n",
    "        train_acc = (pred[train_mask] == labels[train_mask]).float().mean()\n",
    "        val_acc = (pred[val_mask] == labels[val_mask]).float().mean()\n",
    "        test_acc = (pred[test_mask] == labels[test_mask]).float().mean()\n",
    "\n",
    "        # Save the best validation accuracy and the corresponding test accuracy.\n",
    "        if best_val_acc < val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_test_acc = test_acc\n",
    "\n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if e % 5 == 0:\n",
    "            print(\n",
    "                \"In epoch {}, loss: {:.3f}, val acc: {:.3f} (best {:.3f}), test acc: {:.3f} (best {:.3f})\".format(\n",
    "                    e, loss, val_acc, best_val_acc, test_acc, best_test_acc\n",
    "                )\n",
    "            )\n",
    "\n",
    "\n",
    "model = GCN(g.ndata[\"feat\"].shape[1], 16, dataset.num_classes)\n",
    "train(g, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b046f54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dgl",
   "language": "python",
   "name": "dgl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
