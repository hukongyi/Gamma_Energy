{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd33895b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
    "import dgl\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "from dgl.data import DGLDataset\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dgl.nn.pytorch.conv import GINConv\n",
    "from dgl.nn.pytorch.glob import SumPooling, AvgPooling, MaxPooling\n",
    "from tqdm.notebook import tqdm\n",
    "from dgl.data.utils import save_graphs, load_graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2faa87eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d74a6e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = h5py.File(\n",
    "    \"/home2/hky/github/Gamma_Energy/AllSky_originData/Data/gamma_allsky_compress_cuted.h5\",\n",
    "    \"r\",\n",
    ")\n",
    "loc = np.loadtxt(\n",
    "    \"/home2/hky/github/Gamma_Energy/AllSky_originData/TibetIII-forplot.loc\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93fa6386",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MD\n",
      "Tibet\n",
      "age\n",
      "cx\n",
      "cy\n",
      "inout\n",
      "mr1\n",
      "nch\n",
      "ne\n",
      "phi\n",
      "pricx\n",
      "pricy\n",
      "prie\n",
      "prie_num\n",
      "priid\n",
      "prik\n",
      "prine\n",
      "priphi\n",
      "pritheta\n",
      "sigma\n",
      "summd\n",
      "sumpd\n",
      "sumpf\n",
      "theta\n"
     ]
    }
   ],
   "source": [
    "for k in data:\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2063281",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_index, test_index = train_test_split(\n",
    "    range(len(data[\"prie\"])), random_state=42, test_size=0.8\n",
    ")\n",
    "train_index, val_index = train_test_split(\n",
    "    train_val_index, random_state=42, test_size=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc6574d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(savepath, save_index, k):\n",
    "    Tibet = data[\"Tibet\"][:, :, :][save_index]\n",
    "    prie = torch.tensor(\n",
    "        np.log10(data[\"prie\"][:][save_index] / 1000), dtype=torch.float32\n",
    "    )\n",
    "    theta = torch.tensor(data[\"pritheta\"][:][save_index], dtype=torch.float32)\n",
    "    phi = torch.tensor(data[\"priphi\"][:][save_index], dtype=torch.float32)\n",
    "    graphs = list()\n",
    "    for index in tqdm(range(len(prie))):\n",
    "        particle_num = Tibet[index, :, 0]\n",
    "        time = Tibet[index, :, 1]\n",
    "        need = np.where((particle_num >= 0.4) & (np.abs(time) < 800))\n",
    "        nnode = len(need[0])\n",
    "        xdata = np.zeros([nnode, 4], dtype=np.float32)\n",
    "        xdata[:, 0] = np.log10(particle_num[need])\n",
    "        xdata[:, 1] = time[need] / 500\n",
    "        xdata[:, 2] = loc[need][:, 3] / 75\n",
    "        xdata[:, 3] = loc[need][:, 4] / 75\n",
    "\n",
    "        #         src = np.array([n for n in range(nnode) for _ in range(nnode)], dtype=np.int32)\n",
    "        #         dst = np.array(list(range(nnode)) * nnode, dtype=np.int32)\n",
    "        #         need_del = np.where(src == dst)\n",
    "        #         src = np.delete(src, need_del[0])\n",
    "        #         dst = np.delete(dst, need_del[0])\n",
    "        #         src = torch.tensor(src)\n",
    "        #         dst = torch.tensor(dst)\n",
    "        xdata = torch.from_numpy(xdata)\n",
    "        g = dgl.knn_graph(xdata[:, 2:], k=k)\n",
    "        g.ndata[\"xdata\"] = xdata\n",
    "        graphs.append(g)\n",
    "    save_graphs(savepath, graphs, {\"prie\": prie, \"pritheta\": theta, \"priphi\": phi})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "647be4b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a7c16153dad4984a6b0d9613eae511d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/266956 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3df822752f2640ce81cc77e4c1d0cef9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/114411 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c9a6186a610498db4d8cb584c8ef007",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/266956 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6c596d5b2fa4e0dbf2f72df8d1b0228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/114411 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b15ee582ea44be4a8a00c1fc979db18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/266956 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ea5948ed3b74a40bb718ad189f1a6dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/114411 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46c870d608e7411bbde1c46582599826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/266956 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93699a53d1ff49c98b894deeafa9f526",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/114411 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c66c07207dd4140807f370d3fe8aabc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/266956 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/hky/miniconda3/envs/dgl/lib/python3.9/site-packages/dgl/transforms/functional.py:308: DGLWarning: 'k' should be less than or equal to the number of points in 'x'expect k <= 14, got k = 15, use k = 14\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "180b95bb30d049cb8e970ac6fd593f63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/114411 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bb67ff42cf34a7d93616a50b444ad20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/266956 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/hky/miniconda3/envs/dgl/lib/python3.9/site-packages/dgl/transforms/functional.py:308: DGLWarning: 'k' should be less than or equal to the number of points in 'x'expect k <= 15, got k = 16, use k = 15\n",
      "  dgl_warning(\n",
      "/home2/hky/miniconda3/envs/dgl/lib/python3.9/site-packages/dgl/transforms/functional.py:308: DGLWarning: 'k' should be less than or equal to the number of points in 'x'expect k <= 14, got k = 16, use k = 14\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce97f522d5f242ff882acb86cc3a168c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/114411 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for k in range(11, 17):\n",
    "    savepath = f\"/cxtmp/hky/ICRCdata/gamma_train_dgl_knn_{k}.bin\"\n",
    "    create_graph(savepath, train_index, k)\n",
    "    savepath = f\"/cxtmp/hky/ICRCdata/gamma_val_dgl_knn_{k}.bin\"\n",
    "    create_graph(savepath, val_index, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ae39a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# savepath = f\"/cxtmp/hky/ICRCdata/gamma_test_dgl_knn_10.bin\"\n",
    "# create_graph(savepath, test_index, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "414264e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gamma_Allsky_dgl_theta(DGLDataset):\n",
    "    def __init__(self, path):\n",
    "        self.graph, self.labels = load_graphs(path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.graph)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.graph[index], self.labels[\"pritheta\"][index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "854be6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gamma_Allsky_dgl_phi(DGLDataset):\n",
    "    def __init__(self, path):\n",
    "        self.graph, self.labels = load_graphs(path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.graph)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.graph[index], self.labels[\"priphi\"][index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b37dfccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    \"\"\"Construct two-layer MLP-type aggreator for GIN model\"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.linears = nn.ModuleList()\n",
    "        # two-layer MLP\n",
    "        self.linears.append(nn.Linear(input_dim, hidden_dim, bias=False))\n",
    "        self.linears.append(nn.Linear(hidden_dim, output_dim, bias=False))\n",
    "        self.batch_norm = nn.BatchNorm1d((hidden_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = x\n",
    "        h = F.relu(self.batch_norm(self.linears[0](h)))\n",
    "        return self.linears[1](h)\n",
    "\n",
    "\n",
    "class GIN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.ginlayers = nn.ModuleList()\n",
    "        self.batch_norms = nn.ModuleList()\n",
    "        num_layers = 5\n",
    "        # five-layer GCN with two-layer MLP aggregator and sum-neighbor-pooling scheme\n",
    "        for layer in range(num_layers - 1):  # excluding the input layer\n",
    "            if layer == 0:\n",
    "                mlp = MLP(input_dim, hidden_dim, hidden_dim)\n",
    "            else:\n",
    "                mlp = MLP(hidden_dim, hidden_dim, hidden_dim)\n",
    "            self.ginlayers.append(\n",
    "                GINConv(mlp, learn_eps=False)\n",
    "            )  # set to True if learning epsilon\n",
    "            self.batch_norms.append(nn.BatchNorm1d(hidden_dim))\n",
    "        # linear functions for graph sum poolings of output of each layer\n",
    "        self.linear_prediction = nn.ModuleList()\n",
    "        for layer in range(num_layers):\n",
    "            if layer == 0:\n",
    "                self.linear_prediction.append(nn.Linear(input_dim, hidden_dim))\n",
    "            else:\n",
    "                self.linear_prediction.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "        self.drop = nn.Dropout(0)\n",
    "        self.pool = (\n",
    "            MaxPooling()\n",
    "        )  # change to mean readout (AvgPooling) on social network datasets\n",
    "        self.classify = nn.Linear(hidden_dim * num_layers, output_dim * 10)\n",
    "        self.classify2 = nn.Linear(output_dim * 10, output_dim)\n",
    "\n",
    "    def forward(self, g, h):\n",
    "        # list of hidden representation at each layer (including the input layer)\n",
    "        hidden_rep = [h]\n",
    "        for i, layer in enumerate(self.ginlayers):\n",
    "            h = layer(g, h)\n",
    "            h = self.batch_norms[i](h)\n",
    "            h = F.relu(h)\n",
    "            hidden_rep.append(h)\n",
    "        score_over_layer = list()\n",
    "        # perform graph sum pooling over all nodes in each layer\n",
    "        for i, h in enumerate(hidden_rep):\n",
    "            pooled_h = self.pool(g, h)\n",
    "            score_over_layer.append(self.drop(self.linear_prediction[i](pooled_h)))\n",
    "        #             print(score_over_layer[i].shape)\n",
    "        score_over_layer = torch.cat(score_over_layer, dim=1)\n",
    "        score_over_layer = self.classify(score_over_layer)\n",
    "        score_over_layer = self.classify2(score_over_layer).view(-1, 1)\n",
    "        return score_over_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94e828fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn import GraphConv\n",
    "\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, n_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GraphConv(in_dim, hidden_dim)\n",
    "        self.conv2 = GraphConv(hidden_dim, hidden_dim)\n",
    "        self.conv3 = GraphConv(hidden_dim, hidden_dim)\n",
    "        self.classify = nn.Linear(hidden_dim, n_classes)\n",
    "\n",
    "    def forward(self, g, h):\n",
    "        # 应用图卷积和激活函数\n",
    "        h = F.relu(self.conv1(g, h))\n",
    "        h = F.relu(self.conv2(g, h))\n",
    "        h = F.relu(self.conv3(g, h))\n",
    "        with g.local_scope():\n",
    "            g.ndata[\"h\"] = h\n",
    "            # 使用平均读出计算图表示\n",
    "            hg = dgl.readout_nodes(g, \"h\", op=\"mean\")\n",
    "            return self.classify(hg).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6be3abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn import SAGEConv\n",
    "\n",
    "\n",
    "class SAGE(nn.Module):\n",
    "    def __init__(self, in_size, hid_size, out_size):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        # two-layer GraphSAGE-mean\n",
    "        self.layers.append(SAGEConv(in_size, hid_size, \"gcn\"))\n",
    "        self.layers.append(SAGEConv(hid_size, hid_size, \"gcn\"))\n",
    "        self.classify = nn.Linear(hid_size, out_size)\n",
    "        self.dropout = nn.Dropout(0)\n",
    "\n",
    "    def forward(self, graph, x):\n",
    "        h = self.dropout(x)\n",
    "        for l, layer in enumerate(self.layers):\n",
    "            h = layer(graph, h)\n",
    "            if l != len(self.layers) - 1:\n",
    "                h = F.relu(h)\n",
    "                h = self.dropout(h)\n",
    "        with graph.local_scope():\n",
    "            graph.ndata[\"h\"] = h\n",
    "            hg = dgl.readout_nodes(graph, \"h\", op=\"sum\")\n",
    "            return self.classify(hg).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d18c416d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 GCN_10 0.0043012733\n",
      "2 GCN_10 0.00330684\n",
      "3 GCN_10 0.0027624557\n",
      "9 GCN_10 0.0026329819\n",
      "10 GCN_10 0.0024920537\n",
      "11 GCN_10 0.0024908064\n",
      "15 GCN_10 0.002449596\n",
      "19 GCN_10 0.0024315608\n",
      "23 GCN_10 0.0024013096\n",
      "28 GCN_10 0.0022840842\n",
      "45 GCN_10 0.0022834332\n"
     ]
    }
   ],
   "source": [
    "model_name = [\"GCN\"]\n",
    "result = dict()\n",
    "\n",
    "for k in [10]:\n",
    "    train_path = f\"/cxtmp/hky/ICRCdata/gamma_train_dgl_knn_{k}.bin\"\n",
    "    val_path = f\"/cxtmp/hky/ICRCdata/gamma_val_dgl_knn_{k}.bin\"\n",
    "\n",
    "    MCdataset_train = Gamma_Allsky_dgl_theta(train_path)\n",
    "    MCdataset_val = Gamma_Allsky_dgl_theta(val_path)\n",
    "\n",
    "    train_dataloader = GraphDataLoader(\n",
    "        MCdataset_train, batch_size=256, drop_last=False, num_workers=4, shuffle=True\n",
    "    )\n",
    "    val_dataloader = GraphDataLoader(\n",
    "        MCdataset_val, batch_size=256, drop_last=False, num_workers=4, shuffle=False\n",
    "    )\n",
    "\n",
    "    test = next(iter(train_dataloader))\n",
    "    test[0].to(device)\n",
    "\n",
    "    for i, modeltype in enumerate([GIN]):\n",
    "        val_loss_best = 1\n",
    "        model = modeltype(4, 16, 1).to(device)\n",
    "        maxtpoch = 80\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=5e-4)\n",
    "#         lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, maxtpoch)\n",
    "        lossfunction = nn.MSELoss()\n",
    "\n",
    "        for epoch in range(maxtpoch):\n",
    "            model.train()\n",
    "            for batched_graph, labels in train_dataloader:\n",
    "                if batched_graph.num_edges() > 2e8:\n",
    "                    continue\n",
    "                batched_graph, labels = batched_graph.to(device), labels.to(\n",
    "                    device\n",
    "                ).reshape(-1, 1)\n",
    "                pred = model(batched_graph, batched_graph.ndata[\"xdata\"])\n",
    "#                 print(pred)\n",
    "                loss = lossfunction(pred, labels)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            #         print(loss)\n",
    "#             lr_scheduler.step()\n",
    "            y_pred = list()\n",
    "            y_orgin = list()\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for batched_graph, labels in val_dataloader:\n",
    "                    if batched_graph.num_edges() > 2e8:\n",
    "                        continue\n",
    "                    batched_graph, labels = batched_graph.to(device), labels.to(device)\n",
    "                    pred = model(batched_graph, batched_graph.ndata[\"xdata\"])\n",
    "                    y_pred.append(pred.cpu().numpy())\n",
    "                    y_orgin.append(labels.cpu().numpy())\n",
    "            y_pred = np.concatenate(y_pred).reshape(-1)\n",
    "            y_orgin = np.concatenate(y_orgin)\n",
    "            val_loss = np.mean((y_pred - y_orgin) ** 2)\n",
    "#             print(val_loss)\n",
    "            if val_loss < val_loss_best:\n",
    "                val_loss_best = val_loss\n",
    "                torch.save(\n",
    "                    model.state_dict(), f\"/cxtmp/hky/ICRCdata/{model_name[i]}_{k}_Adam_theta.pt\"\n",
    "                )\n",
    "                result[f\"{model_name[i]}_{k}\"] = val_loss_best\n",
    "                print(f\"{epoch} {model_name[i]}_{k}\", val_loss_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8fab7898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 GIN_10 0.9413977\n",
      "1 GIN_10 0.8155389\n",
      "2 GIN_10 0.7411396\n",
      "3 GIN_10 0.7282139\n",
      "4 GIN_10 0.6664024\n",
      "6 GIN_10 0.59304225\n",
      "9 GIN_10 0.56118214\n",
      "11 GIN_10 0.55218863\n",
      "13 GIN_10 0.53893536\n",
      "15 GIN_10 0.52019083\n",
      "16 GIN_10 0.5184756\n",
      "18 GIN_10 0.51200813\n",
      "22 GIN_10 0.5060405\n",
      "23 GIN_10 0.5047889\n",
      "24 GIN_10 0.49546263\n",
      "27 GIN_10 0.49521294\n",
      "28 GIN_10 0.49038473\n",
      "31 GIN_10 0.4806886\n",
      "32 GIN_10 0.47020364\n",
      "34 GIN_10 0.46531537\n",
      "39 GIN_10 0.4640966\n",
      "42 GIN_10 0.451309\n",
      "50 GIN_10 0.44785112\n",
      "51 GIN_10 0.4451235\n",
      "58 GIN_10 0.43717495\n",
      "66 GIN_10 0.43587935\n",
      "73 GIN_10 0.43558577\n",
      "76 GIN_10 0.43119606\n"
     ]
    }
   ],
   "source": [
    "model_name = [\"GIN\"]\n",
    "result = dict()\n",
    "\n",
    "for k in [10]:\n",
    "    train_path = f\"/cxtmp/hky/ICRCdata/gamma_train_dgl_knn_{k}.bin\"\n",
    "    val_path = f\"/cxtmp/hky/ICRCdata/gamma_val_dgl_knn_{k}.bin\"\n",
    "\n",
    "    MCdataset_train = Gamma_Allsky_dgl_phi(train_path)\n",
    "    MCdataset_val = Gamma_Allsky_dgl_phi(val_path)\n",
    "\n",
    "    train_dataloader = GraphDataLoader(\n",
    "        MCdataset_train, batch_size=256, drop_last=False, num_workers=4, shuffle=True\n",
    "    )\n",
    "    val_dataloader = GraphDataLoader(\n",
    "        MCdataset_val, batch_size=256, drop_last=False, num_workers=4, shuffle=False\n",
    "    )\n",
    "\n",
    "    test = next(iter(train_dataloader))\n",
    "    test[0].to(device)\n",
    "\n",
    "    for i, modeltype in enumerate([GIN]):\n",
    "        val_loss_best = 1\n",
    "        model = modeltype(4, 16, 1).to(device)\n",
    "        maxtpoch = 80\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=5e-4)\n",
    "#         lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, maxtpoch)\n",
    "        lossfunction = nn.MSELoss()\n",
    "\n",
    "        for epoch in range(maxtpoch):\n",
    "            model.train()\n",
    "            for batched_graph, labels in train_dataloader:\n",
    "                if batched_graph.num_edges() > 2e8:\n",
    "                    continue\n",
    "                batched_graph, labels = batched_graph.to(device), labels.to(\n",
    "                    device\n",
    "                ).reshape(-1, 1)\n",
    "                pred = model(batched_graph, batched_graph.ndata[\"xdata\"])\n",
    "#                 print(pred)\n",
    "                loss = lossfunction(pred, labels)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            #         print(loss)\n",
    "#             lr_scheduler.step()\n",
    "            y_pred = list()\n",
    "            y_orgin = list()\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for batched_graph, labels in val_dataloader:\n",
    "                    if batched_graph.num_edges() > 2e8:\n",
    "                        continue\n",
    "                    batched_graph, labels = batched_graph.to(device), labels.to(device)\n",
    "                    pred = model(batched_graph, batched_graph.ndata[\"xdata\"])\n",
    "                    y_pred.append(pred.cpu().numpy())\n",
    "                    y_orgin.append(labels.cpu().numpy())\n",
    "            y_pred = np.concatenate(y_pred).reshape(-1)\n",
    "            y_orgin = np.concatenate(y_orgin)\n",
    "            val_loss = np.mean((y_pred - y_orgin) ** 2)\n",
    "#             print(val_loss)\n",
    "            if val_loss < val_loss_best:\n",
    "                val_loss_best = val_loss\n",
    "                torch.save(\n",
    "                    model.state_dict(), f\"/cxtmp/hky/ICRCdata/{model_name[i]}_{k}_Adam_phi.pt\"\n",
    "                )\n",
    "                result[f\"{model_name[i]}_{k}\"] = val_loss_best\n",
    "                print(f\"{epoch} {model_name[i]}_{k}\", val_loss_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15438847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'GIN_10': 0.0023323353}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb6d352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_loss_list =list()\n",
    "# for i in result.keys():\n",
    "#     val_loss_list.append(result[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7df5737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_Energy = GIN(4, 16, 1).to(device)\n",
    "model_theta = GIN(4, 16, 1).to(device)\n",
    "model_phi = GIN(4, 16, 1).to(device)\n",
    "model_Energy.load_state_dict(torch.load( f\"/cxtmp/hky/ICRCdata/GIN_{10}_Adam_new.pt\"))\n",
    "model_theta.load_state_dict(torch.load( f\"/cxtmp/hky/ICRCdata/GIN_{10}_Adam_theta.pt\"))\n",
    "model_phi.load_state_dict(torch.load( f\"/cxtmp/hky/ICRCdata/GIN_{10}_Adam_phi.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7c16ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = f\"/cxtmp/hky/ICRCdata/gamma_test_dgl_knn_{10}.bin\"\n",
    "\n",
    "MCdataset_test = Gamma_Allsky_dgl_theta(test_path)\n",
    "\n",
    "test_dataloader = GraphDataLoader(\n",
    "    MCdataset_test, batch_size=256, drop_last=False, num_workers=4, shuffle=False\n",
    ")\n",
    "model.eval()\n",
    "y_pred_Energy = list()\n",
    "y_pred_theta = list()\n",
    "y_pred_phi = list()\n",
    "with torch.no_grad():\n",
    "    for batched_graph, labels in test_dataloader:\n",
    "        if batched_graph.num_edges() > 2e8:\n",
    "            continue\n",
    "        batched_graph = batched_graph.to(device)\n",
    "        pred_Energy = model_Energy(batched_graph, batched_graph.ndata[\"xdata\"])\n",
    "        pred_theta = model_theta(batched_graph, batched_graph.ndata[\"xdata\"])\n",
    "        pred_phi = model_phi(batched_graph, batched_graph.ndata[\"xdata\"])\n",
    "        y_pred_Energy.append(pred_Energy.cpu().numpy())\n",
    "        y_pred_theta.append(pred_theta.cpu().numpy())\n",
    "        y_pred_phi.append(pred_phi.cpu().numpy())\n",
    "y_pred_Energy = np.concatenate(y_pred_Energy).reshape(-1)\n",
    "y_pred_theta = np.concatenate(y_pred_theta).reshape(-1)\n",
    "y_pred_phi = np.concatenate(y_pred_phi).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e79f3725",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata = dict()\n",
    "for para in data:\n",
    "    if para not in [\"Tibet\",\"MD\"]:\n",
    "        newdata[para] = data[para][:][test_index]\n",
    "newdata[\"GIN_Energy\"] = y_pred_Energy\n",
    "newdata[\"GIN_theta\"] = y_pred_theta\n",
    "newdata[\"GIN_phi\"] = y_pred_phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "68135c6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': array([0.78757978, 0.83530966, 1.27184005, ..., 0.89952723, 0.7238766 ,\n",
       "        0.49854519]),\n",
       " 'cx': array([  40.96136429,  -41.24355796,   75.02616021, ...,   56.33998744,\n",
       "         -49.17675182, -102.2785714 ]),\n",
       " 'cy': array([-36.42954179, -12.18750573,  38.72055522, ...,  60.5955183 ,\n",
       "         51.85961624, -23.84869615]),\n",
       " 'inout': array([1, 1, 1, ..., 1, 1, 1], dtype=int32),\n",
       " 'mr1': array([53.49270138, 39.2244279 , 55.67924866, ..., 32.19611886,\n",
       "        22.8512814 , 37.28707292]),\n",
       " 'nch': array([245,  79,  21, ...,  18,  27,  17], dtype=int32),\n",
       " 'ne': array([377564.75061167,  42075.86744255,  18202.78948356, ...,\n",
       "         10265.07668486,  13640.2677972 ,  47703.04731955]),\n",
       " 'phi': array([-16.17095853,  79.31958072,  16.67024746, ...,  74.77165179,\n",
       "        -32.64360104, -32.34111811]),\n",
       " 'pricx': array([  41.806,  -42.46 ,  103.752, ...,   41.81 ,  -49.914, -111.22 ]),\n",
       " 'pricy': array([-37.194, -11.746,  54.75 , ...,  70.018,  52.007, -21.886]),\n",
       " 'prie': array([319951.4375    , 127101.53125   ,  38058.44140625, ...,\n",
       "         22703.57617188,   7715.96728516,  27349.84765625]),\n",
       " 'prie_num': array([ 198, 7941, 7858, ..., 1788, 7288, 8617]),\n",
       " 'priid': array([1, 1, 1, ..., 1, 1, 1]),\n",
       " 'prik': array([7, 7, 4, ..., 4, 1, 8], dtype=int32),\n",
       " 'prine': array([196985,  31917,  19006, ...,   5323,   5452,  20474]),\n",
       " 'priphi': array([-2.86239862,  1.7550838 ,  2.87343931, ...,  1.829826  ,\n",
       "        -2.54034495, -2.57980227]),\n",
       " 'pritheta': array([0.49271756, 0.77253866, 0.47028086, ..., 0.65557355, 0.25026506,\n",
       "        0.51741898]),\n",
       " 'sigma': array([0.37081884, 0.39709193, 0.40250821, ..., 0.38825418, 0.32465493,\n",
       "        0.19011809]),\n",
       " 'summd': array([0.        , 2.27740091, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]),\n",
       " 'sumpd': array([1340.99663056,  253.31457328,   85.87879939, ...,   48.32492242,\n",
       "          24.01983241,  133.81292331]),\n",
       " 'sumpf': array([4134.84415676,  790.29320235,  148.42094796, ...,   94.70946967,\n",
       "         216.58998494,  176.85122206]),\n",
       " 'theta': array([28.32037032, 44.6084495 , 27.48062128, ..., 37.38032497,\n",
       "        14.41590893, 30.0323652 ]),\n",
       " 'GIN_Energy': array([2.6071572, 1.9940695, 1.7790371, ..., 1.2344004, 1.0032972,\n",
       "        1.6633214], dtype=float32),\n",
       " 'GIN_theta': array([0.52281654, 0.7126536 , 0.5942308 , ..., 0.7112091 , 0.27098614,\n",
       "        0.5978011 ], dtype=float32),\n",
       " 'GIN_phi': array([-3.4565141,  1.9868453,  1.5244572, ...,  2.3291848, -1.7029977,\n",
       "        -2.8398871], dtype=float32)}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c786f5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(f\"/cxtmp/hky/ICRCdata/gamma_test_with_dgl.npz\",**newdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca996e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dgl",
   "language": "python",
   "name": "dgl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
